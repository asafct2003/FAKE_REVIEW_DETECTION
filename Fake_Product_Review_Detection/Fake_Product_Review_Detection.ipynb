{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885027eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asafc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Download stopwords if missing\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b814d37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully\n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5     5.0    CG   \n",
      "1  Home_and_Kitchen_5     5.0    CG   \n",
      "2  Home_and_Kitchen_5     5.0    CG   \n",
      "3  Home_and_Kitchen_5     1.0    CG   \n",
      "4  Home_and_Kitchen_5     5.0    CG   \n",
      "\n",
      "                                               text_  \n",
      "0  Love this!  Well made, sturdy, and very comfor...  \n",
      "1  love it, a great upgrade from the original.  I...  \n",
      "2  This pillow saved my back. I love the look and...  \n",
      "3  Missing information on how to use it, but it i...  \n",
      "4  Very nice set. Good quality. We have had the s...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40432 entries, 0 to 40431\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   category  40432 non-null  object \n",
      " 1   rating    40432 non-null  float64\n",
      " 2   label     40432 non-null  object \n",
      " 3   text_     40432 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"fake_reviews.csv\")   # Use your dataset file name\n",
    "\n",
    "print(\"Dataset Loaded Successfully\")\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a4795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417878a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['rating'].hist()\n",
    "# plt.title(\"Rating distribution\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc1a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_len'] = df['text_'].str.len()\n",
    "# sns.histplot(df['text_len'], bins=50)\n",
    "# plt.title(\"Review length distribution\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea804f",
   "metadata": {},
   "source": [
    "Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e70b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import string\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# stop = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_text(s):\n",
    "#     s = str(s).lower()\n",
    "#     s = re.sub(r\"http\\S+|www\\S+\",\"\", s)\n",
    "#     s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "#     s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "#     tokens = [w for w in s.split() if w not in stop]\n",
    "#     return \" \".join(tokens)\n",
    "\n",
    "# df['text_clean'] = df['text_'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8992f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer(max_features=30000, ngram_range=(1,2))\n",
    "# X_tfidf = tfidf.fit_transform(df['text_clean'])\n",
    "# y = df['label'].map({'CG':1,'OR':0}).values   # adjust mapping if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7060fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# MAX_WORDS = 30000\n",
    "# MAX_LEN = 200\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=MAX_WORDS)\n",
    "# tokenizer.fit_on_texts(df['text_clean'])\n",
    "# seqs = tokenizer.texts_to_sequences(df['text_clean'])\n",
    "# X_seq = pad_sequences(seqs, maxlen=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf48d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== TEXT CLEANING FUNCTION =====================\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()                                      # Lowercase\n",
    "    s = re.sub(r\"http\\S+|www\\S+\", \"\", s)                    # Remove links\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)                      # Remove symbols\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()                      # Normalize spaces\n",
    "    tokens = [w for w in s.split() if w not in stop]        # Remove stopwords\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b334d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text sample:\n",
      "0    love well made sturdy comfortable love pretty\n",
      "1    love great upgrade original mine couple years\n",
      "2          pillow saved back love look feel pillow\n",
      "3      missing information use great product price\n",
      "4             nice set good quality set two months\n",
      "Name: text_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ===================== APPLY CLEANING =====================\n",
    "df[\"text_clean\"] = df[\"text_\"].apply(clean_text)\n",
    "\n",
    "print(\"Cleaned text sample:\")\n",
    "print(df[\"text_clean\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85366872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    20216\n",
      "0    20216\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===================== LABEL MAPPING =====================\n",
    "# CG = Fake Review = 1\n",
    "# OR = Real Review = 0\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map({\"CG\": 1, \"OR\": 0})\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff0169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Shape: (40432, 30000)\n"
     ]
    }
   ],
   "source": [
    "# ===================== TF-IDF VECTORIZER =====================\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(df[\"text_clean\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "print(\"TF-IDF Shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "013d9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== TRAIN TEST SPLIT =====================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5822a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Completed\n"
     ]
    }
   ],
   "source": [
    "# ===================== TRAIN MODEL =====================\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model Training Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9e016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9063929763818475\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      4044\n",
      "           1       0.92      0.90      0.91      4043\n",
      "\n",
      "    accuracy                           0.91      8087\n",
      "   macro avg       0.91      0.91      0.91      8087\n",
      "weighted avg       0.91      0.91      0.91      8087\n",
      "\n",
      "\n",
      "Sample probabilities:\n",
      "[[0.24644097 0.75355903]\n",
      " [0.61503535 0.38496465]\n",
      " [0.05146581 0.94853419]\n",
      " [0.78654542 0.21345458]\n",
      " [0.94409653 0.05590347]]\n"
     ]
    }
   ],
   "source": [
    "# ===================== MODEL EVALUATION =====================\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Show sample probabilities\n",
    "print(\"\\nSample probabilities:\")\n",
    "print(lr.predict_proba(X_test)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f41041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model and TF-IDF vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ===================== SAVE MODEL & VECTORIZER =====================\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(lr, \"models/lr_tfidf_model.joblib\")\n",
    "joblib.dump(tfidf, \"models/tfidf_vectorizer.joblib\")\n",
    "\n",
    "print(\"\\n✅ Model and TF-IDF vectorizer saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general_env)",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
